{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# MNIST Autoencoder\nwe copy the previous model and train it to reconstruct the images through a compressed layer with 20 neurons  "
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": "import tensorflow\nfrom tensorflow import keras\n \nfrom IPython.display import Image\n#Image(\"img/picture.png\")\n\nimport numpy as np \nimport os"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": "def Encoder():\n    return keras.models.Sequential([\n      keras.layers.Input(784),\n      keras.layers.Dense(128, 'relu'),\n      keras.layers.Dense(128, 'relu'),\n      keras.layers.Dense(20)\n    ])"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": "def Decoder():\n    return keras.models.Sequential([\n        keras.layers.Input(20),\n        keras.layers.Dense(128, 'relu'),\n        keras.layers.Dense(128, 'relu'),\n        keras.layers.Dense(784)\n    ])"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": "class AutoEncoder:\n    def __init__(self, dataset, encoder, decoder):\n        self.encoder = encoder\n        self.decoder = decoder\n        self.dataset = dataset\n                \n        self.model = keras.models.Sequential([\n            keras.layers.Flatten((28, 28)),\n            self.encoder,\n            self.decoder\n        ])\n        \n    def train(self, epochs):\n        self.model.compile(optimizer='sgd', loss='mse')\n        self.model.fit(self.dataset, self.dataset, epochs)\n        \n    def save(self):\n        if not os.path.exists(r'./weights'):\n            os.mkdir(r'./weights')\n        \n        self.encoder.save(r'./weights/encoder_weights.h5')\n        self.decoder.save(r'./weights/decoder_weights.h5')\n        self.model.save(r'./weights/autoencoder_weights.h5')\n        "
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": "encoder = Encoder()\ndecoder = Decoder()"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": "mnist = keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f471a4558add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-0c7f556ad6cc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, encoder, decoder)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         self.model = keras.models.Sequential([\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/layers/core.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_format, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/utils/conv_utils.pyc\u001b[0m in \u001b[0;36mnormalize_data_format\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     raise ValueError('The `data_format` argument must be one of '\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'lower'"
     ]
    }
   ],
   "source": "autoencoder = AutoEncoder(x_test, encoder, decoder)\nautoencoder.train(20)"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2.860066"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "loss_fn(y_train[:1], predictions).numpy()"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples\nEpoch 1/10\n60000/60000 [==============================] - 2s 36us/sample - loss: 0.0842 - accuracy: 0.9754\nEpoch 2/10\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0796 - accuracy: 0.9767\nEpoch 3/10\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0787 - accuracy: 0.9779\nEpoch 4/10\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0789 - accuracy: 0.9773\nEpoch 5/10\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0787 - accuracy: 0.9769\nEpoch 6/10\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0773 - accuracy: 0.9772\nEpoch 7/10\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0779 - accuracy: 0.9776\nEpoch 8/10\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0771 - accuracy: 0.9776\nEpoch 9/10\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0773 - accuracy: 0.9779\nEpoch 10/10\n60000/60000 [==============================] - 2s 34us/sample - loss: 0.0764 - accuracy: 0.9780\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f771438b2d0>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "model.compile(optimizer='adagrad',\n              loss=loss_fn,\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=10)"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10000/10000 - 0s - loss: 0.0774 - accuracy: 0.9759\n"
    },
    {
     "data": {
      "text/plain": "[0.077365882361494, 0.9759]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "model.evaluate(x_test,  y_test, verbose=2)"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": "probability_model = tf.keras.Sequential([\n  model,\n  tf.keras.layers.Softmax()\n])"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\narray([[1.7775214e-06, 2.1200778e-07, 5.8084566e-05, 4.9587409e-04,\n        1.7050207e-09, 1.0310017e-06, 1.3847021e-10, 9.9942327e-01,\n        1.6101353e-06, 1.8292361e-05],\n       [7.2365192e-06, 4.8177415e-05, 9.9987054e-01, 5.5735829e-05,\n        1.6934277e-11, 2.2823460e-06, 8.5385427e-06, 1.9773572e-11,\n        7.4363288e-06, 1.1999643e-10],\n       [3.8173384e-06, 9.9391574e-01, 1.2627323e-03, 1.2169211e-04,\n        1.5102653e-04, 1.9276398e-04, 2.4419528e-04, 3.2455870e-03,\n        8.3998829e-04, 2.2473281e-05],\n       [9.9973565e-01, 1.3350994e-08, 4.3296910e-05, 1.3020258e-06,\n        2.5441653e-07, 3.2307194e-05, 2.2206505e-05, 1.5296122e-04,\n        3.3448674e-07, 1.1525638e-05],\n       [1.9110669e-04, 7.6036855e-07, 2.6382634e-04, 8.0831078e-06,\n        9.7731459e-01, 1.2192727e-05, 1.0677170e-04, 8.2742062e-04,\n        3.9634971e-05, 2.1235537e-02]], dtype=float32)>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "probability_model(x_test[:5])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
